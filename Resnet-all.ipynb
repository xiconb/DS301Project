{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import RandomSampler\n",
    "from torchvision.datasets import ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes:  200\n",
      "Total train images:  29435\n",
      "Total valid images:  1000\n",
      "Total test images:  1000\n"
     ]
    }
   ],
   "source": [
    "DIR_TRAIN = \"./train/\"\n",
    "DIR_VALID = \"./valid/\"\n",
    "DIR_TEST = \"./test/\"\n",
    "classes = os.listdir(DIR_TRAIN)\n",
    "print(\"Total Classes: \",len(classes))\n",
    "\n",
    "#Counting total train, valid & test images\n",
    "\n",
    "train_count = 0\n",
    "valid_count = 0\n",
    "test_count = 0\n",
    "for _class in classes:\n",
    "    train_count += len(os.listdir(DIR_TRAIN + _class))\n",
    "    valid_count += len(os.listdir(DIR_VALID + _class))\n",
    "    test_count += len(os.listdir(DIR_TEST + _class))\n",
    "\n",
    "print(\"Total train images: \",train_count)\n",
    "print(\"Total valid images: \",valid_count)\n",
    "print(\"Total test images: \",test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = []\n",
    "valid_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes:\n",
    "    \n",
    "    for img in os.listdir(DIR_TRAIN + _class):\n",
    "        train_imgs.append(DIR_TRAIN + _class + \"/\" + img)\n",
    "    \n",
    "    for img in os.listdir(DIR_VALID + _class):\n",
    "        valid_imgs.append(DIR_VALID + _class + \"/\" + img)\n",
    "        \n",
    "    for img in os.listdir(DIR_TEST + _class):\n",
    "        test_imgs.append(DIR_TEST + _class + \"/\" + img)\n",
    "\n",
    "class_to_int = {classes[i] : i for i in range(len(classes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root = DIR_TRAIN, transform = T.ToTensor())\n",
    "valid_dataset = ImageFolder(root = DIR_VALID, transform = T.ToTensor())\n",
    "test_dataset = ImageFolder(root = DIR_TEST, transform = T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = models.resnet18(pretrained=True)\n",
    "# turn training false for all layers, other than fc layer\n",
    "for param in model_res.parameters():\n",
    "    param.requires_grad = False\n",
    "class NNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet, self).__init__()\n",
    "        # TODO\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3*224*224, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.35),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.35),\n",
    "            nn.Linear(512, 200),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for training networks')\n",
    "    parser.add_argument('-seed', type=int, default=1, help='random seed')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='num epochs')\n",
    "    parser.add_argument('-batch', type=int, default=16, help='batch size')\n",
    "    parser.add_argument('-lr', type=float, default=0.01, help='learning rate')\n",
    "    parser.add_argument('-drop', type=float, default=0.3, help='drop rate')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "def load_data(batch_size=16):\n",
    "    trainset = train_dataset\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=64,\n",
    "        shuffle=True,\n",
    "        #sampler=train_random_sampler,\n",
    "        num_workers=10,pin_memory=True)\n",
    "    testset = test_dataset\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=32,\n",
    "        shuffle=False,\n",
    "        #sampler=test_random_sampler,\n",
    "        num_workers=10,pin_memory=True)\n",
    "    validset = valid_dataset\n",
    "    validloader = torch.utils.data.DataLoader(\n",
    "        validset, batch_size=32, \n",
    "        shuffle=False,\n",
    "        #sampler=valid_random_sampler,\n",
    "        num_workers=10, pin_memory=True)\n",
    "    return trainloader, testloader, validloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([32, 3, 224, 224])\n",
      "Shape of y:  torch.Size([32]) torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [15:01<00:00,  1.96s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training loss: 4.632 training accuracy: 16.032%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [14:57<00:00,  1.95s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training loss: 3.345 training accuracy: 51.082%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [15:04<00:00,  1.97s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 training loss: 2.515 training accuracy: 68.198%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [14:46<00:00,  1.93s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 training loss: 1.984 training accuracy: 75.916%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [14:51<00:00,  1.94s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 training loss: 1.637 training accuracy: 79.857%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [14:58<00:00,  1.95s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 training loss: 1.401 training accuracy: 82.558%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [14:51<00:00,  1.94s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 training loss: 1.230 training accuracy: 84.247%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [14:57<00:00,  1.95s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 training loss: 1.106 training accuracy: 85.358%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [14:07<00:00,  1.84s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 training loss: 1.008 training accuracy: 86.339%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████████████| 460/460 [14:32<00:00,  1.90s/b]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 training loss: 0.931 training accuracy: 87.026%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████████████████████████████████████████████████| 32/32 [00:31<00:00,  1.01b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test set: 91.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(net, trainloader, num_epochs=2):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        running_loss, total,  correct = 0.0, 0, 0\n",
    "        for images, labels in tqdm(\n",
    "                trainloader, desc='Epoch '+str(epoch), unit='b'):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        loss = running_loss / len(trainloader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print('Epoch %d training loss: %.3f training accuracy: %.3f%%' % (\n",
    "            epoch, loss, accuracy))\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for images, labels in tqdm(testloader, desc='Test', unit='b'):\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test set: %.2f%%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "args = get_args()\n",
    "set_random(args.seed)\n",
    "#trainloader, testloader = load_data(args.batch)\n",
    "trainloader, testloader, validloader = load_data(args.batch)\n",
    "for X, y in testloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break\n",
    "#net = NNet()\n",
    "model_res.fc=nn.Linear(512,200)\n",
    "### Get device\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_res.to(device)\n",
    "train(model_res, trainloader, 10)\n",
    "test(model_res, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
